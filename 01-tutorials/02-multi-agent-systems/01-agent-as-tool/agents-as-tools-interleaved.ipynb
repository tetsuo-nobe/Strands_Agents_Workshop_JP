{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strands Agents SDK と Claude 4 Interleaved Thinkingを活用したツールとしてのエージェント\n",
    "\n",
    "このノートブックでは、Strands Agents SDK と Claude 4の**インターリーブ思考**機能を活用して、専門エージェントによるインテリジェントなワークフローを構築する方法を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インターリーブ思考を理解する\n",
    "\n",
    "### インターリーブ思考とは？\n",
    "\n",
    "インターリーブ思考は、Claude 4モデルの新機能で、モデルに以下の機能を提供します。\n",
    "\n",
    "1. **ツール呼び出しの間に考える**：次のステップを決定する前に、結果を処理および推論する\n",
    "2. **推論によって複数のツールを連鎖させる**：高度な複数ステップの意思決定を行う\n",
    "3. **戦略を動的に適応させる**：中間結果に基づいてアプローチを変更する\n",
    "\n",
    "### 仕組み\n",
    "\n",
    "インターリーブ思考を適用したエージェントのイベントループと適用しないエージェントのイベントループには、多くの類似点があります。\n",
    "```\n",
    "クエリ → LLMが思考中 -> LLMがツールの呼び出しを決定 -> イベントループがツールを呼び出す -> 出力がLLMに返される -> [ LLMがツールを呼び出す必要がなくなるまでこれが続き、最終回答がレンダリングされます ]\n",
    "```\n",
    "\n",
    "インターリーブ思考で気付く主な違いは、イベントループがLLMの「決定」ではなく「思考」に基づいて動作する点です。上記のループの2番目のリンク、「thinking（思考）」に注目してください。従来のイベントループでは、思考は隠蔽されます。LLMがツールを呼び出す決定を下すか、最終回答を出すまで待たなければなりません。\n",
    "\n",
    "インターリーブ思考の場合、LLMは2番目のステップ（「LLMは思考中」）にある間に、その思考をイベントループに「漏らし」ます。そして、イベントループはLLMがツールの実行を「考える」とすぐにツールを実行するように構成されています。つまり、LLMが思考を終える頃には、最初の「決定」で最終回答が実際に得られているということです。\n",
    "\n",
    "### インターリーブ思考の有効化\n",
    "\n",
    "Strands と Bedrock でこの機能を有効にするには、以下の手順に従います。\n",
    "- `temperature=1` を設定します（思考が有効な場合は必須です）\n",
    "- ベータヘッダーを追加します: `\"anthropic_beta\": [\"interleaved-thinking-2025-05-14\"]`\n",
    "- 推論予算を設定します: `\"reasoning_config\": {\"type\": \"enabled\", \"budget_tokens\": 3000}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップとインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 専門エージェントをツールとして定義\n",
    "\n",
    "まず、Strands `@tool` デコレータを使用して、4つの専門エージェントを作成します。\n",
    "- **リサーチャー**: 事実情報を収集します\n",
    "- **データアナリスト**: 情報を処理および分析します\n",
    "- **ファクトチェッカー**: 情報の正確性を検証します\n",
    "- **レポート作成者**: 洗練された最終文書を作成します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strands @tool デコレータを使用してツールとして実装された専門エージェント\n",
    "@tool\n",
    "def researcher(query: str) -> str:\n",
    "    \"\"\"\n",
    "    事実情報を収集する研究専門家。\n",
    "\n",
    "    引数:\n",
    "      クエリ: 調査する研究課題またはトピック\n",
    "\n",
    "    戻り値:\n",
    "      研究結果と情報源\n",
    "    \"\"\"\n",
    "    # 集中的なリサーチエージェントを作成する\n",
    "    # 注: 各呼び出しは新しいエージェントインスタンス（ステートレス）を作成します。\n",
    "    research_agent = Agent(\n",
    "        system_prompt=\"あなたは研究の専門家です。事実に基づいた情報を収集し、可能な場合は出典を明記してください。回答は200語以内に収めてください。\",\n",
    "        callback_handler=None  # ツールエージェントのストリーミングなし\n",
    "    )\n",
    "    \n",
    "    # リサーチタスクを実行する\n",
    "    result = research_agent(f\"Research: {query}\")\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def data_analyst(data: str) -> str:\n",
    "    \"\"\"\n",
    "    情報を処理・分析するデータアナリスト。\n",
    "\n",
    "    引数:\n",
    "      データ: 分析対象となる生データまたは調査結果\n",
    "\n",
    "    戻り値:\n",
    "      洞察とパターンに基づく分析\n",
    "    \"\"\"\n",
    "    # アナリストエージェントは洞察の抽出に重点を置く\n",
    "    analysis_agent = Agent(\n",
    "        system_prompt=\"あなたはデータアナリストです。重要なインサイトを抽出し、パターンを特定し、分析的な結論を提示してください。実用的なインサイトに焦点を当ててください。\",\n",
    "        callback_handler=None\n",
    "    )\n",
    "    \n",
    "    # 提供されたデータを分析\n",
    "    result = analysis_agent(f\"次のデータを分析して洞察を提供してください: {data}\")\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def fact_checker(information: str) -> str:\n",
    "    \"\"\"\n",
    "    情報の正確性を検証するファクトチェッカー。\n",
    "\n",
    "    引数:\n",
    "      情報: 検証する主張またはデータ\n",
    "\n",
    "    戻り値:\n",
    "      正確性評価を含むファクトチェック結果\n",
    "    \"\"\"\n",
    "    # 検証のためのファクトチェックエージェント\n",
    "    fact_check_agent = Agent(\n",
    "        system_prompt=\"あなたはファクトチェッカーです。主張を検証し、信憑性を評価し、信頼度を算出してください。疑わしい記述があれば特定してください。\",\n",
    "        callback_handler=None\n",
    "    )\n",
    "    \n",
    "    # 情報を確認\n",
    "    result = fact_check_agent(f\"次の情報を事実確認します: {information}\")\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def report_writer(analysis: str) -> str:\n",
    "    \"\"\"\n",
    "    洗練された最終文書を作成するレポートライター。\n",
    "\n",
    "    引数:\n",
    "      分析: 分析されたデータと洞察\n",
    "\n",
    "    戻り値:\n",
    "      フォーマットされた最終レポート\n",
    "    \"\"\"\n",
    "    # プロフェッショナルな作品を生み出すライターエージェント\n",
    "    writer_agent = Agent(\n",
    "        system_prompt=\"あなたはプロのレポートライターです。エグゼクティブサマリーと実用的な推奨事項を盛り込んだ、明確で構造化されたレポートを作成して下さい。\",\n",
    "        callback_handler=None\n",
    "    )\n",
    "    \n",
    "    # レポートを作成\n",
    "    result = writer_agent(f\"次に基づいてプロフェッショナルなレポートを作成します。 {analysis}\")\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インターリーブ思考を用いたClaude 4オーケストレーター\n",
    "\n",
    "次に、インターリーブ思考を用いて専門エージェントをインテリジェントに連携させるClaude 4エージェントであるオーケストレーターを作成します。\n",
    "\n",
    "### オーケストレーターの動作：\n",
    "\n",
    "1. ユーザーから高レベルのタスクを受け取ります。\n",
    "2. 必要な情報について**検討**します。\n",
    "3. 初期データを収集するために研究者ツールを呼び出します。\n",
    "4. 調査結果と必要な分析について**検討**します。\n",
    "5. データアナリストを呼び出して調査結果を処理します。\n",
    "6. 正確性と検証の必要性について**検討**します。\n",
    "7. 必要に応じてファクトチェッカーを呼び出します。\n",
    "8. 調査結果の提示方法について**検討**します。\n",
    "9. 最終出力のためにレポート作成者を呼び出します。\n",
    "10. 回答前にワークフロー全体を**検討**します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロード4 ストランドを用いたインターリーブ思考によるオーケストレーター\n",
    "class StrandsInterlevedWorkflowOrchestrator:\n",
    "    def __init__(self):\n",
    "        # インテリジェントなワークフロー調整のためのオーケストレーターシステムプロンプトを定義する\n",
    "        self.system_prompt = \"\"\"あなたは、専門エージェントにアクセスできるインテリジェントなワークフローオーケストレーターです。\n",
    "        あなたの役割は、これらの専門エージェントを活用して、ワークフローをインテリジェントに調整することです。\n",
    "        - リサーチャー：あらゆるトピックに関する事実情報を収集します。\n",
    "        - データアナリスト：データを分析し、洞察を抽出します。\n",
    "        - ファクトチェッカー：情報の正確性を検証します。\n",
    "        - レポートライター：洗練された最終レポートを作成します。\n",
    "        \"\"\"\n",
    "    \n",
    "    def run_workflow(self, task: str, enable_interleaved_thinking: bool = True) -> str:\n",
    "        \"\"\"指定されたタスクに対してインテリジェントなワークフローを実行します。\n",
    "\n",
    "        引数:\n",
    "          task: 完了するタスク\n",
    "          enable_interleaved_thinking: インターリーブ思考を有効にするかどうか (デフォルト: True)\n",
    "\n",
    "        オーケストレーターは以下の処理を行います。\n",
    "        1. タスク要件を理解する\n",
    "        2. 最適なアプローチを検討する\n",
    "        3. 専門エージェントを調整する\n",
    "        4. ステップ間の結果を反映する\n",
    "        5. 包括的な出力を生成する\n",
    "        \"\"\"\n",
    "        thinking_mode = \"WITH interleaved thinking\" if enable_interleaved_thinking else \"WITHOUT interleaved thinking\"\n",
    "        print(f\"\\nStarting intelligent workflow {thinking_mode} for: {task}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Bedrock 経由で Claude 4 をインターリーブ思考の有無で構成\n",
    "        if enable_interleaved_thinking:\n",
    "            claude4_model = BedrockModel(\n",
    "                model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "                max_tokens=4096,\n",
    "                temperature=1,  # 思考が有効な場合は1である必要がある\n",
    "                additional_request_fields={\n",
    "                    # インターリーブ思考ベータ機能を有効にする\n",
    "                    \"anthropic_beta\": [\"interleaved-thinking-2025-05-14\"],\n",
    "                    # 推論パラメータを設定\n",
    "                    \"reasoning_config\": {\n",
    "                        \"type\": \"enabled\",  # 思考をオンにする\n",
    "                        \"budget_tokens\": 3000  # トークンバジェット\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            claude4_model = BedrockModel(\n",
    "                model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "                max_tokens=4096,\n",
    "                temperature=1\n",
    "            )\n",
    "        \n",
    "        # Claude 4と専門ツールを使ってオーケストレーターエージェントを作成する\n",
    "        orchestrator = Agent(\n",
    "            model=claude4_model,\n",
    "            system_prompt=self.system_prompt,\n",
    "            tools=[researcher, data_analyst, fact_checker, report_writer]\n",
    "        )\n",
    "        \n",
    "        prompt = f\"\"\"インテリジェントなワークフロー調整を使用して、このタスクを完了してください: {task}\n",
    "\n",
    "        手順:\n",
    "        1. このタスクを達成するために必要な情報を慎重に検討してください。\n",
    "        2. 専門エージェントを戦略的に活用してください。それぞれに独自の強みがあります。\n",
    "        3. 各ツールの使用後、結果を振り返り、アプローチを調整してください。\n",
    "        4. 包括的な結果を得るために、必要に応じて複数のエージェントを調整してください。\n",
    "        5. 必要に応じて事実確認を行い、正確性を確保してください。\n",
    "        6. すべての側面を網羅した包括的な最終回答を提供してください。\n",
    "\n",
    "        覚えておいてください: ツール呼び出しの合間にじっくり考えることで、より良い意思決定が可能になります。\n",
    "        計画、結果の評価、戦略の調整に活用してください。\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            result = orchestrator(prompt)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"Workflow failed: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## デモを実行する\n",
    "\n",
    "オーケストレーターの動作を見てみましょう！オーケストレーターがどのように考え、考えながらツールを呼び出すのかを見てみましょう。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オーケストレーターを作成する\n",
    "print(\"Strands Agents SDK: Claude 4 Interleaved Thinking Workflow Demo\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    orchestrator = StrandsInterlevedWorkflowOrchestrator()\n",
    "    print(\"✅ Orchestrator initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to initialize orchestrator: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストケースでワークフローを実行\n",
    "test_case = \"リモートワークが生産性に与える影響を分析し、戦略的な推奨事項を提供します\"\n",
    "\n",
    "print(f\"📋 Task: {test_case}\\n\")\n",
    "\n",
    "try:\n",
    "    result = orchestrator.run_workflow(test_case)\n",
    "    \n",
    "    print(f\"\\n📊 Workflow Result:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Workflow execution failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インターリーブ思考を無効にして試す\n",
    "\n",
    "オーケストレーターを呼び出して、インターリーブ思考を無効にして実験してみましょう。出力の違いを観察します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# では、インターリーブ思考なしで同じタスクを試してみましょう\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🔄 Now running the same task WITHOUT interleaved thinking\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    result_without_thinking = orchestrator.run_workflow(test_case, enable_interleaved_thinking=False)\n",
    "    \n",
    "    print(f\"\\n📊 Workflow Result (Without Interleaved Thinking):\")\n",
    "    print(\"=\" * 70)\n",
    "    print(result_without_thinking)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Workflow execution failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
